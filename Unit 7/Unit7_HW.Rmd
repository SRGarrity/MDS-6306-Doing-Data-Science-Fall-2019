---
title: "HWUnit7"
author: "Steven Garrity"
date: "10/9/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(jsonlite)
library(RCurl)
library(XML)
library(ggplot2)
library(GGally)
library(tidyverse)
library(e1071)
```

# Question 1:
```{r}
# library(jsonlite)
# library(RCurl)
# library(XML)

### Import and tidy the data
data <-getURL("https://public.opendatasoft.com/api/records/1.0/search/?dataset=titanic-passengers&rows=2000&facet=survived&facet=pclass&facet=sex&facet=age&facet=embarked")

temp <- fromJSON(data, flatten = FALSE)
class(temp) # it is a list.

df <- as.data.frame(temp$records$fields)
df$survived <- as.factor(df$survived)
rm(temp, data)

### Perform a little EDA
# library(ggplot2)
# library(GGally)
# library(tidyverse)

df %>% select(age, pclass, survived) %>% ggpairs(aes(color=survived, alpha=0.2)) + ggtitle("Titantic Survival")
```

# Classify using NB classifier
```{r}
# library(e1071)
for_NB <- df %>% select(age,pclass,survived) # just the data we need for initial NB classifier

model = naiveBayes(survived~.,data = for_NB)
predictions <- predict(model,for_NB[,c(1,2)])

# df = data.frame(Outlook = "Rain", Wind = "Hi")
# predict(model,df) #just classifications

# calculate the posterior probability:
predict(model,df, type = "raw") #gives probabilities 
```

# Train a NB model based on the training set using just the Age and Pclass variables. Use the model to predict the survival of those in the test set and use those results to evaluate the model based on accuracy, sensitivity and specificity. Finally, Compare the results to what you found with the KNN classifier. (At least one slide.)
```{r}
dfClean = df %>% select(age,pclass,survived) %>% filter(!is.na(age) & !is.na(pclass))
set.seed(4)
trainIndices = sample(seq(1:length(dfClean$age)),round(.7*length(dfClean$age)))
trainTitanic = dfClean[trainIndices,]
testTitanic = dfClean[-trainIndices,]

head(trainTitanic)
head(testTitanic)

model = naiveBayes(survived~.,data = trainTitanic)

table(predict(model,testTitanic[,c(1,2)]),testTitanic$survived)
confusionMatrix(table(predict(model,testTitanic[,c(1,2)]),testTitanic$survived))
```

# Refit NB model to Titanic dataset with 100 iterations
```{r}
dfClean = df %>% select(age,pclass,survived) %>% filter(!is.na(age) & !is.na(pclass))

iterations = 100
masterAcc = matrix(nrow = iterations)
masterSensitivity = matrix(nrow = iterations)
masterSpecificity = matrix(nrow = iterations)
splitPerc = 0.70 # Train/Test split

for(j in 1:iterations)
{
  # set.seed(floor(runif(1,1,100)))
  trainIndices = sample(seq(1:length(dfClean$age)),round(.7*length(dfClean$age)))
  trainTitanic = dfClean[trainIndices,]
  testTitanic = dfClean[-trainIndices,]
  
  model = naiveBayes(trainTitanic[,c(1,2)],trainTitanic$survived)
  table(predict(model,testTitanic[,c(1,2)]),testTitanic$survived)
  CM = confusionMatrix(table(predict(model,testTitanic[,c(1,2)]),testTitanic$survived))
  masterAcc[j] = CM$overall[1]
  masterSensitivity[j] = CM$byClass[1]
  masterSpecificity[j] = CM$byClass[2]
}

MeanAcc = colMeans(masterAcc)
MeanSensitivity = colMeans(masterSensitivity)
MeanSpecificity = colMeans(masterSpecificity)
MeanAcc
MeanSensitivity
MeanSpecificity

hist(masterAcc, xlab="Model Accuracies")
hist(masterSensitivity, xlab = "Model Sensitivities")
hist(masterSpecificity, xlab = "Model Specificities")

table(predict(model,test[,c(1,2)]),test$Species)
confusionMatrix(table(predict(model,test[,c(1,2)]),test$Species))
```

# Now add Sex to the model so that it has Age, Pclass and Sex in the NB model.  Use the trainTitanic(set.seed(4)) dataframe to train the model and create a confusion matrix using the testTitanic dataframe.  In addition, find the Accuracy, Sensitivity and Specificity. (1 slide)
```{r}
dfClean = df %>% select(age,pclass,sex,survived) %>% filter(!is.na(age) & !is.na(pclass) & !is.na(sex))

dfClean$sexN = ifelse(dfClean$sex == "male",0,1)
dfClean <- dfClean[-3]
dfClean <- dfClean[c(1,2,4,3)]
str(dfClean)

set.seed(4)
trainIndices = sample(seq(1:length(dfClean$age)),round(.7*length(dfClean$age)))
trainTitanic = dfClean[trainIndices,]
testTitanic = dfClean[-trainIndices,]

head(trainTitanic)
head(testTitanic)

model = naiveBayes(survived~.,data = trainTitanic)

table(predict(model,testTitanic[,c(1,3)]),testTitanic$survived)
confusionMatrix(table(predict(model,testTitanic[,c(1,3)]),testTitanic$survived))
```

# Repeat above, using a random seed over 100 iterations
```{r}
dfClean = df %>% select(age,pclass,sex,survived) %>% filter(!is.na(age) & !is.na(pclass) & !is.na(sex))

dfClean$sexN = ifelse(dfClean$sex == "male",0,1)
dfClean <- dfClean[-3]
dfClean <- dfClean[c(1,2,4,3)]
str(dfClean)

iterations = 100
masterAcc = matrix(nrow = iterations)
masterSensitivity = matrix(nrow = iterations)
masterSpecificity = matrix(nrow = iterations)
splitPerc = 0.70 # Train/Test split

for(j in 1:iterations)
{
  # set.seed(floor(runif(1,1,100)))
  trainIndices = sample(seq(1:length(dfClean$age)),round(.7*length(dfClean$age)))
  trainTitanic = dfClean[trainIndices,]
  testTitanic = dfClean[-trainIndices,]
  
  model = naiveBayes(trainTitanic[,c(1,3)],trainTitanic$survived)
  table(predict(model,testTitanic[,c(1,3)]),testTitanic$survived)
  CM = confusionMatrix(table(predict(model,testTitanic[,c(1,3)]),testTitanic$survived))
  masterAcc[j] = CM$overall[1]
  masterSensitivity[j] = CM$byClass[1]
  masterSpecificity[j] = CM$byClass[2]
}

MeanAcc = colMeans(masterAcc)
MeanSensitivity = colMeans(masterSensitivity)
MeanSpecificity = colMeans(masterSpecificity)
MeanAcc
MeanSensitivity
MeanSpecificity

hist(masterAcc, xlab="Model Accuracies")
hist(masterSensitivity, xlab = "Model Sensitivities")
hist(masterSpecificity, xlab = "Model Specificities")

table(predict(model,test[,c(1,2)]),test$Species)
confusionMatrix(table(predict(model,test[,c(1,2)]),test$Species))
```


# Part 2: For the full (multinomial) IRIS data (the iris dataset in R), do a 70-30 train/test cross validation and use sepal length and width as predictors.  Generate 100 different train/test splits and calculate the average accuracy, sensitivity and specificity.  Compare the average accuracy to that to the KNN model you used in Unit 6.
```{r}
iris_forNB = iris %>% select(Sepal.Length, Sepal.Width, Species)
summary(iris_forNB)

iterations = 100
masterAcc = matrix(nrow = iterations)
splitPerc = 0.70 # Train/Test split

for(j in 1:iterations)
{
  trainIndices = sample(1:dim(iris_forNB)[1],round(splitPerc * dim(iris_forNB)[1]))
  train = iris_forNB[trainIndices,]
  test = iris_forNB[-trainIndices,]
  
  model = naiveBayes(train[,c(1,2)],train$Species)
  table(predict(model,test[,c(1,2)]),test$Species)
  CM = confusionMatrix(table(predict(model,test[,c(1,2)]),test$Species))
  masterAcc[j] = CM$overall[1]
}

MeanAcc = colMeans(masterAcc)
MeanAcc

hist(masterAcc, xlab="Model Accuracies")

table(predict(model,test[,c(1,2)]),test$Species)
confusionMatrix(table(predict(model,test[,c(1,2)]),test$Species))
```
