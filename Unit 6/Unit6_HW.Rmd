---
title: "DDS Unit 6 HW"
author: "Steven Garrity"
date: "9/29/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1 - Titanic Dataset (woohoo, a classic!)
```{r}
library(jsonlite)
library(RCurl)
library(XML)

### Import and tidy the data
data <-getURL("https://public.opendatasoft.com/api/records/1.0/search/?dataset=titanic-passengers&rows=2000&facet=survived&facet=pclass&facet=sex&facet=age&facet=embarked")

temp <- fromJSON(data, flatten = FALSE)
class(temp) # it is a list.

df <- as.data.frame(temp$records$fields)
df$survived <- as.factor(df$survived)
rm(temp, data)

### Perform a little EDA
library(ggplot2)
library(tidyverse)

df %>% ggplot(aes(x=age, fill=pclass)) +
  geom_histogram() +
  facet_wrap(~survived)

df %>% ggplot(aes(x=age, y=pclass, col=survived)) +
  geom_point()


### Apply k-NN classifier. Classify died/did-not-die based on age and class.
library(class)
library(caret)
library(e1071)

#### First, omit any rows where one of the observations is NA
df_reduced <- df %>% select(age, pclass, survived) %>% na.omit()
df_reduced_scaled <- data.frame(Zage = scale(df_reduced$age), Zpclass = scale(df_reduced$pclass), 
                       Survived = df_reduced$survived)

splitPerc = .75
trainIndices = sample(1:dim(df_reduced_scaled)[1],round(splitPerc * dim(df_reduced_scaled)[1]))
train = df_reduced_scaled[trainIndices,]
test = df_reduced_scaled[-trainIndices,]
dim(train)
str(train)
dim(test)
str(test)

### set up loop to tune the "k" hyperparameter
accs = data.frame(accuracy = numeric(30), k = numeric(30))

for(i in 1:30)
{
  classifications = knn(train[,c(1,2)], test[,c(1,2)], train$Survived, prob = TRUE, k = i)
  table(test$Survived,classifications)
  CM = confusionMatrix(table(test$Survived,classifications))
  accs$accuracy[i] = CM$overall[1]
  accs$k[i] = i
}

plot(accs$k,accs$accuracy, type = "l", xlab = "k")

###
iterations = 250
numks = 100

masterAcc = matrix(nrow = iterations, ncol = numks)
  
for(j in 1:iterations)
{
accs = data.frame(accuracy = numeric(30), k = numeric(30))
trainIndices = sample(1:dim(df_reduced_scaled)[1],round(splitPerc * dim(df_reduced_scaled)[1]))
train = df_reduced_scaled[trainIndices,]
test = df_reduced_scaled[-trainIndices,]
for(i in 1:numks)
{
  classifications = knn(train[,c(1,2)],test[,c(1,2)],train$Survived, prob = TRUE, k = i)
  table(classifications,test$Survived)
  CM = confusionMatrix(table(classifications,test$Survived))
  masterAcc[j,i] = CM$overall[1]
}

}

MeanAcc = colMeans(masterAcc)

plot(seq(1,numks,1),MeanAcc, type = "l")

which.max(MeanAcc)


###



classifications <- knn.cv(df_reduced_scaled[,1:2],df_reduced_scaled$Survived, k = 60, prob = TRUE)
confusionMatrix(classifications,df_reduced$survived)
class_probabilities <- attr(classifications, 'prob') # we can extract probabilities for each prediction. They are stored as an attribute of the "classifications" variable.

table(classifications ,df_reduced_scaled$Survived)

### predict self-survival based on age...iterate for each class (need to scale!!!)

scaled_age <- scale(c(min(df_reduced$age), 40, max(df_reduced$age)))
scaled_class <- scale(c(1,2,3))

for (i in 1:length(scaled_class))
{
  age_class = data.frame(Age = scaled_age[2], Class = scaled_class[i])
  print(knn(df_reduced_scaled[,1:2], age_class, df_reduced_scaled$Survived, k = 60, prob = TRUE))
}
  

```

